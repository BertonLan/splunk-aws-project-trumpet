Indistiguishable from magic: Sending AWS CloudTrail and Config data to Splunk with a serverless applicationSplunk's new serverless application for AWS CloudTrail and AWS Config data ingestion is now available on the AWS Serverless Application Repository. You can use this serverless application is a streamlined way to set up most of the AWS side architecture needed to send CloudTrail to Splunk. After you deploy this serverless app, you can imagine yourself as a magician pulling a multi-account, multi-region, push based, data streaming architecture out of a hat. It's no rabbit, (or pony) but still pretty cool.What's in the hat?Now, a magician never reveals his secrets, but I'm no magician, so here's what's happening under the covers. As you may already know, a serverless application is a CloudFormation template that leverages AWS's Serverless Application Model (SAM) to spin up AWS resources. This serverless application in particular will create a fully configured AWS Kinesis Firehose Stream, and an AWS Lambda function to populate the Firehose Stream with events from CloudTrail. All that is left to do after the serverless application has deployed is to create the Lambda trigger for the S3 bucket that CloudTrail pushes data to. After that is set up, any CloudTrail event that gets pushed to that bucket will be streamed to Splunk. I'll walk you through the steps below.PrerequisitesFirst, make sure you have a top hat, a deck of cards, and a magic wand. Really though, you'll need an HTTP Event Collector endpoint with an enabled HEC token. Additionally, the Kinesis Firehose Stream to Splunk delivery mechanism requires the HEC endpoint to be terminated with a valid CA-signed certificate matching the DNS hostname used to connect to your HEC endpoint. You'll also want the name of the S3 bucket that is being populated with events from a CloudTrail trail.Deploying the serverless applicationApplications from the Serverless Application Repository are accessible from the AWS Lambda console. From the console, click "Create function", then select Serverless Application Repository from the available starting options. This will open a list of available actions in the repository, type for "Splunk" in the search bar, and select the application called splunk-cloudtrail-firehose from the results. Enter in the fields you created or found in the prerequisites section of this blog into the "Configure application parameters" section. Now hit deploy and go read Reddit or Hacker News, or your choice of 30 second time killer (here's a version of Reddit that looks like you're reviewing some code).Now that you're back and the serverless application has fully deployed, let's create an S3 trigger that will kick off our lambda function and the rest of the streaming process. In the AWS S3 console, open up the bucket configuration settings for the bucket that you provided during the setup of the serverless application.Create a notification event for the s3 bucket that pushes any ObjectCreated event to the Lambda function that was created by the serverless application. The exact configuration options are in the image below, but you can tweak these as needed.Let's go back to Splunk and watch as our dat flows in. Let's search for the aws:cloudtrail sourcetype in the Splunk search bar (sourcetype="aws:cloudtrail"). you should see your CloudTrail events begin to populate.That's it!This serverless aplication magic trick might not be something you can break out at a dinner party, but if you have tried to configure this streaming architecture manually before, I hope you'll agree that this serverless application is a little bit magical. Splunk has an assortment of these for a variety of AWS services and architectures that you can use to kick start the process of ingesting AWS data into Splunk. Check them all out here and have a look at two previous blog posts where we looked at sending ELB application access logs and GuardDuty findings to Splunk over HEC.